{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gensim) (1.3.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gensim) (1.16.5)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.11.5)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.1)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (1.14.5)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from botocore<1.15.0,>=1.14.5->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from botocore<1.15.0,>=1.14.5->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(5, 1), (7, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(0, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)],\n",
       " [(5, 1), (7, 1), (8, 1), (9, 1), (10, 1), (20, 1), (21, 1), (22, 1), (23, 1)],\n",
       " [(5, 1), (7, 1), (9, 1), (10, 1), (11, 1), (24, 1), (25, 1), (26, 1)],\n",
       " [(27, 1), (28, 1), (29, 1)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "my_documents = ['The movie was about a spaceship and aliens.',\n",
    "               'I really liked the movie!',\n",
    "               'Avesom actoin scenes, but boring characters.',\n",
    "               'The movie was awful! I hate alien films',\n",
    "               'Space is cool! I liked the movie',\n",
    "               'More spaces filmsPlease']\n",
    "tokenized_docs = [word_tokenize(doc.lower())for doc in my_documents]\n",
    "dictionary = Dictionary(tokenized_docs)\n",
    "dictionary.token2id\n",
    "corpus = [dictionary.doc2bow(doc)for doc in tokenized_docs]\n",
    "corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "tfidf = TfidfModel(corpus)\n",
    "tfidf = [corpus[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  In/IN\n",
      "  (GPE New/NNP York/NNP)\n",
      "  ,/,\n",
      "  I/PRP\n",
      "  like/VBP\n",
      "  to/TO\n",
      "  ride/VB\n",
      "  the/DT\n",
      "  (ORGANIZATION Metro/NNP)\n",
      "  to/TO\n",
      "  visit/VB\n",
      "  (ORGANIZATION MOMA/NNP)\n",
      "  and/CC\n",
      "  some/DT\n",
      "  restaurents/NNS\n",
      "  rated/VBN\n",
      "  well/RB\n",
      "  by/IN\n",
      "  (PERSON Ruth/NNP Reichl/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sentence = \"In New York, I like to ride the Metro to visit MOMA and some restaurents rated well by Ruth Reichl.\"\n",
    "tokenized_sent = nltk.word_tokenize(sentence)\n",
    "#Tag each tokenized sentence in to parts of speech\n",
    "tagged_sent = nltk.pos_tag(tokenized_sent)\n",
    "tagged_sent[:3]\n",
    "print(nltk.ne_chunk(tagged_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NE Bharatiya/NNP Janata/NNP Party/NNP)\n",
      "(NE Rajya/NNP Sabha/NNP)\n",
      "(NE Opposition/NNP)\n",
      "(NE Bangladesh/NNP)\n",
      "(NE Pakistan/NNP)\n"
     ]
    }
   ],
   "source": [
    "#Load a scraped news article\n",
    "article = open('nlp_ner.txt','r').read()\n",
    "type(article)\n",
    "# article\n",
    "\n",
    "# #Tokenize the article into sentences:sentences\n",
    "setences = nltk.sent_tokenize(article)\n",
    "# print(setences)\n",
    "# #Tokenize each sentences in to words:token_sentences\n",
    "token_sentences = [nltk.word_tokenize(sent)for sent in setences]\n",
    "# token_sentences\n",
    "# #Tag each tokenized sentences into parts of speech: pos_sentences \n",
    "pos_sentences = [nltk.pos_tag(sent)for sent in token_sentences]\n",
    "pos_sentences\n",
    "# #Create the named entity chunks: chunked_sentences\n",
    "chunked_sentences = nltk.ne_chunk_sents(pos_sentences,binary=True)\n",
    "# chunked_sentences\n",
    "# #Test for steams of the tree with \"NE\" tags\n",
    "for sent in chunked_sentences:\n",
    "    for chunk in sent:\n",
    "        if hasattr(chunk,\"label\")and chunk.label()==\"NE\":\n",
    "            print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
